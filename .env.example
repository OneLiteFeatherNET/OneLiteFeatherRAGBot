# Copy to .env and fill in secrets/configs. This file is a template and should never be committed with real credentials.

# --- Discord Bot ---
APP_DISCORD_TOKEN=
APP_BOT_STATUS="OneLiteFeather RAG"
APP_GUILD_IDS=[]
APP_ENABLE_MESSAGE_CONTENT_INTENT=false

# Role-based admin control (optional, works in addition to Discord administrators)
APP_ADMIN_ROLE_IDS=[]
APP_ADMIN_ROLE_NAMES=[]

# --- AI provider selection ---
APP_AI_PROVIDER=openai  # openai | ollama | vllm
APP_LLM_MODEL=gpt-4.1-mini
APP_EMBED_MODEL=text-embedding-3-small
APP_TEMPERATURE=0.1
APP_EMBED_PROVIDER=openai
APP_LLM_SYSTEM_PROMPT=

# Optional: override provider endpoints
APP_OLLAMA_BASE_URL=http://localhost:11434
APP_VLLM_BASE_URL=http://localhost:8000/v1
APP_VLLM_API_KEY=
OPENAI_API_KEY=

# --- GitHub API (used by orgs/issues/listing) ---
GITHUB_TOKEN=

# --- Postgres / pgvector ---
APP_PG_HOST=localhost
APP_PG_PORT=5432
APP_PG_USER=postgres
APP_PG_PASSWORD=postgres
APP_PG_DATABASE=postgres

# --- RAG table & behavior ---
APP_TABLE_NAME=rag_chunks
APP_EMBED_DIM=1536
APP_TOP_K=6
APP_RAG_FALLBACK_TO_LLM=true
APP_RAG_MIX_LLM_WITH_RAG=false
APP_RAG_MIX_THRESHOLD=
APP_RAG_SCORE_KIND=similarity
APP_RAG_MODE=auto
APP_RAG_GATE_STRATEGY=llm
APP_RAG_GATE_THRESHOLD=
APP_RAG_MIN_QUESTION_LEN=12

# --- UI/messages (user-facing text; customizable) ---
# Optional extra style appended to the system prompt (e.g. sarcasm, emoji usage)
APP_CHAT_STYLE_APPEND=
# Placeholder message shown while answering
APP_REPLY_PLACEHOLDER_TEXT="ðŸ§  Einen kleinen Moment â€“ ich suche passende Informationen und schreibe die Antwort â€¦"
# Language hint template appended when language is detected; {lang} placeholder is replaced
APP_LANGUAGE_HINT_TEMPLATE="Antwortsprache: {lang}"
# Headings/prefixes used in responses
APP_SOURCES_HEADING="Sources:"
APP_REPLY_CONTEXT_LABEL="Context (previous bot message):"
APP_MEMORY_SUMMARY_HEADING="Nutzerprofil (Zusammenfassung):"
APP_MEMORY_RECENT_HEADING="Letzte Unterhaltungsschritte:"
APP_MEMORY_USER_PREFIX="User"
APP_MEMORY_BOT_PREFIX="Bot"

# --- Ingestion defaults ---
APP_INGEST_EXTS=[".md", ".py", ".yml", ".yaml", ".toml", ".json", ".txt", ".java"]

# --- Queue + ETL ---
APP_JOB_BACKEND=rabbitmq  # postgres (local) or rabbitmq (recommended for scale)
APP_RABBITMQ_URL=
APP_RABBITMQ_QUEUE=rag_jobs
APP_QUEUE_WATCH_POLL_SEC=5.0
APP_ETL_STAGING_BACKEND=s3  # local | s3
APP_ETL_STAGING_DIR=.staging
APP_S3_STAGING_BUCKET=
APP_S3_STAGING_PREFIX=manifests
APP_S3_REGION=us-east-1
APP_S3_ENDPOINT_URL=
APP_S3_ACCESS_KEY_ID=
APP_S3_SECRET_ACCESS_KEY=

# --- Health & metrics ---
APP_HEALTH_HTTP_PORT=8080

# --- Credits & Budgeting ---
# Enable credits/budget enforcement
APP_CREDIT_ENABLED=false
# Global monthly cap across all users (credits per month)
APP_CREDIT_GLOBAL_CAP=100000
# Default per-user monthly limit (overridden by ranks or per-user override)
APP_CREDIT_DEFAULT_LIMIT=1000
# Rank limits as JSON, e.g.: {"gold": 5000, "silver": 2000}
APP_CREDIT_RANK_LIMITS={}
# Map role name to rank as JSON, e.g.: {"Gold": "gold", "VIP": "gold"}
APP_CREDIT_ROLE_RANKS_BY_NAME={}
# Map role ID (string) to rank as JSON, e.g.: {"123456": "gold"}
APP_CREDIT_ROLE_RANKS_BY_ID={}
# Roles treated as unlimited (still respects global cap)
APP_CREDIT_UNLIMITED_ROLE_NAMES=[]
APP_CREDIT_UNLIMITED_ROLE_IDS=[]
# Estimation parameters
APP_CREDIT_TOKENS_PER_CHAR=0.25
APP_CREDIT_EST_OUTPUT_TOKENS=600
APP_CREDIT_PER_1K_TOKENS=1.0
# Label when mixing LLM response into RAG answer (optional)
APP_RAG_MIX_LABEL=
