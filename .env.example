# Copy to .env and fill in secrets/configs. This file is a template and should never be committed with real credentials.

# --- Discord Bot ---
APP_DISCORD_TOKEN=
APP_BOT_STATUS="OneLiteFeather RAG"
APP_GUILD_IDS=[]
APP_ENABLE_MESSAGE_CONTENT_INTENT=false

# Role-based admin control (optional, works in addition to Discord administrators)
APP_ADMIN_ROLE_IDS=[]
APP_ADMIN_ROLE_NAMES=[]

# --- AI provider selection ---
APP_AI_PROVIDER=openai  # openai | ollama | vllm
APP_LLM_MODEL=gpt-4.1-mini
APP_EMBED_MODEL=text-embedding-3-small
APP_TEMPERATURE=0.1
APP_EMBED_PROVIDER=openai
APP_LLM_SYSTEM_PROMPT=

# Optional: override provider endpoints
APP_OLLAMA_BASE_URL=http://localhost:11434
APP_VLLM_BASE_URL=http://localhost:8000/v1
APP_VLLM_API_KEY=
OPENAI_API_KEY=

# --- GitHub API (used by orgs/issues/listing) ---
GITHUB_TOKEN=

# --- Postgres / pgvector ---
APP_PG_HOST=localhost
APP_PG_PORT=5432
APP_PG_USER=postgres
APP_PG_PASSWORD=postgres
APP_PG_DATABASE=postgres

# --- RAG table & behavior ---
APP_TABLE_NAME=rag_chunks
APP_EMBED_DIM=1536
APP_TOP_K=6
APP_RAG_FALLBACK_TO_LLM=true
APP_RAG_MIX_LLM_WITH_RAG=false
APP_RAG_MIX_THRESHOLD=
APP_RAG_SCORE_KIND=similarity
APP_RAG_MODE=auto
APP_RAG_GATE_STRATEGY=llm
APP_RAG_GATE_THRESHOLD=
APP_RAG_MIN_QUESTION_LEN=12

# --- Ingestion defaults ---
APP_INGEST_EXTS=[".md", ".py", ".yml", ".yaml", ".toml", ".json", ".txt", ".java"]

# --- Queue + ETL ---
APP_JOB_BACKEND=rabbitmq  # postgres (local) or rabbitmq (recommended for scale)
APP_RABBITMQ_URL=
APP_RABBITMQ_QUEUE=rag_jobs
APP_QUEUE_WATCH_POLL_SEC=5.0
APP_ETL_STAGING_BACKEND=s3  # local | s3
APP_ETL_STAGING_DIR=.staging
APP_S3_STAGING_BUCKET=
APP_S3_STAGING_PREFIX=manifests
APP_S3_REGION=us-east-1
APP_S3_ENDPOINT_URL=
APP_S3_ACCESS_KEY_ID=
APP_S3_SECRET_ACCESS_KEY=

# --- Health & metrics ---
APP_HEALTH_HTTP_PORT=8080
